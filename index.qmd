---
title: "Writing a great story for data science projects - Fall 2025 "
subtitle: "This is a Report Template Quarto"
author: "Namita Mishra (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!

Nice report!
:::

## Introduction

1. 

What is the goal of the paper?
The authors aimed to develop a bayesian hierarchical model for multivariate longitudinal data to predict the health status, trajectory, and likely intervention effects for each member of a clinical population in the PCORI mission, and to address questions about health care from patients and clinicians.

Why is it important?
Medical data includes DNA sequences, functional images of the brain, patient-reported outcomes and the electronic health record capturing patient’s sequence of health measurements, diagnoses, and treatments. Full use of the electronic health record (EHR) of patients could improve diagnostic accuracy and prediction of treatment effects, since the standard approaches for analyzing clinical data are not adequate for this purpose. 
The bayesian hierarchical model combines diverse sources of prior knowledge and patient data with evidence, to predict the patient’s health status, trajectory, and/or likely benefits of interventions. Visualizations of characteristics of posterior distributions can be immediately understood by clinicians and patients as relevant to their decision.

How is it solved? – methods
They applied Bayesian hierarchical regression for multivariate longitudinal patient data using open-source R-packages was developed 2 levels—time within person and persons within a population
The model comprised: the effects of exogenous (eg, age, clinical history) and endogenous (eg, current treatment) variables on the individual’s health status; multivariate health measurements for health status; the effects of health measurements at one time on subsequent interventions.
The model produces an estimate of the posterior distribution of the trend in health status for each value of the predictor variables and produces an estimate of the marginal distribution of the regression coefficients; each coefficient measures how the outcome, health status, is associated with its predictor variable (R, X).
In a larger sample, the likelihood dominates the prior distribution for key parameters such as regression coefficients. The bayesian hierarchical model is adaptable because (1) it is a likelihood-based approach.(2) use of priors (prior laboratory and clinical trials data) provide a reasonable range for the assay sensitivities that, once imposed through the prior assumptions, make the model identifiable (3) Markov chain Monte Carlo (MCMC) estimate the posterior distributions to avoid missing data and complex outcome measurements.

Results/limitations, if any.
Three case studies on pneumonia etiology in children, prostate cancer, and major mental disorders, were chosen to provide different challenges to the model development. In Prostate Cancer Case Study to correctly identify low risk patient population, they developed and applied hierarchical model to possibly reduce the risk overtreatment, complications and adverse effects from treatment, as well as financial burden, for patients (Disease reclassification). Prostate cancer software was then implemented within the JHM HER.
Limitation: the models were entirely parametric and recommend extensions to nonparametric or more flexible parametric models. To have improved approach for neuroimage or genomic data.[@Zeger2020Using]


2.	
What is the goal of the paper?
The authors aim to apply computational tool implementing Bayesian inference to calculate the posterior probability of disease diagnosis to develop three modules designed to define and compare parametric (with a fixed set of parameters)  and nonparametric distributions (which do not make a priori assumptions about the distribution’s mathematical form) and analyses National Health and Nutrition Examination Survey datasets from two separate diagnostic tests on both diseased and nondiseased populations. 

Why is it important?
Medical diagnosis is crucial for treatment and management decisions and uses conventional methods for diagnosis using clinical criteria and fixed numerical thresholds limits capturing other information about the intricate relations between diagnostic tests and the varying prevalence of diseases. The probability distributions associated with quantitative diagnostic test outcomes often demonstrate some overlap between the diseased and nondiseased groups. Dichotomous method fail to capture the complexity and heterogeneity of disease presentations across diverse populations. The applicability of the normal distribution in conventional method is critiqued, especially when dealing with clinical measurands that exhibit skewness, bimodality, or multimodality

How is it solved? – methods
To authors explored and developed specialized computational tool employing Bayesian inference (Bayesian diagnostic approach is) to calculate the posterior probability of disease diagnosis in theWolfram Language.
Bayesian paradigm, calculates and integrate prior probabilities of disease with distributions of diagnostic measurands in both diseased and nondiseased populations, the approach enables the evaluation of the information conveyed via diagnostic measurements and the combination of data from multiple diagnostic tests, to improve diagnostic accuracy and precision while introducing flexibility, adaptability, and versatility into the diagnostic process. The foundational data is crucial in establishing the essential context against which new diagnostic measurements can be compared and the absence of such normative data could potentially compromise the reliability and validity of Bayesian diagnostic methods.

Results/limitations, if any.
Nonparametric Bayesian models produce a better fit to data distributions, considering limited existing literature and emphasizes the robustness in capturing complex data distributions.
The nonparametric Bayesian probabilities for disease exhibited multimodal patterns,
in contrast to the bimodal, double sigmoidal curves generated by parametric models.

Limitations: 
•	The models were entirely parametric and recommend extensions to nonparametric or more flexible parametric models and aim to improv approach for neuroimage or genomic data.
•	Due to limited availability of scholarly publications is an issue with over-dependence on Prior Probabilities 
•	Elevated Uncertainty due to insufficient data contributes to broader confidence intervals in the computed posterior probabilities
•	Systemic bias due to unrepresentative datasets compromise the fidelity of Bayesian calculations.
•	Given the lack of comprehensive data, it is pertinent to combine Bayesian methods with other statistical and computational techniques for better diagnostic modalities. [@Chatzimichail2023]



3.	
What is the goal of the paper?
The study describes the stages of Bayesian analysis, specifying the prior and data models, deriving inference, model checking and refinement by discussing the importance of prior and posterior predictive checking, selecting a proper sampling technique from a posterior distribution, variational inference and variable selection and its application across various research fields. The study proposes strategies for reproducibility and reporting standards, outlining an updated WAMBS (when to Worry and how to Avoid the Misuse of Bayesian Statistics) checklist and also outline the impact of Bayesian analysis on artificial intelligence in the future. 

Why is it important?
Bayesian statistics is suitable for quantitative researchers working across a broad range of science-related areas that have at least some knowledge of regression modelling. We
How is it solved? – methods
The study classified the priors into three categories based on the degree of (un)certainty (hyperparameters) surrounding the population parameter value: informative, weakly informative and diffuse. 
The prior has its distribution as N( μ0 , σ^ 20) where a larger variance represents a greater amount of uncertainty surrounding. Prior elicitation (experts, generic expert, data -based, sample data using methods such as maximum likelihood or sample statistics, etc) constructed prior distribution. 
Prior sensitivity analysis of the likelihood, to examine different forms of the model assess how the priors and the likelihood align and help understand the impact of the prior settings on posterior estimates, reflecting the variation not captured by the prior or likelihood alone. Prior estimation allow for data-informed shrinkage, enact regularization or influence algorithms towards a likely high-density region and improve estimation efficiency. Knowing the exact probabilistic specification of the priors for a complex model with smaller sample sizes is important as small sample convey less information, compared to priors. 
To quantify the strength of observed data lends to possible value(s) for the unknown parameter(s). 
 
In Bayesian inference, unknown parameters (random variables) have values that are varied while the (observed) data have values that are fixed, and the likelihood is a function of θ for the fixed data y. Therefore, the likelihood function summarizes a statistical model that stochastically generates all of the data, a range of possible values for θ and the observed data y.With having the prior, the likelihood, and the data, we obtain posterior distribution we model to the data to estimate the unknown parameters of the model. The model captures the primary factors that we wish to improve our understanding of. 
Monte Carlo integration technique provide integrals using computer simulations of sampled values from a given distribution.The author mentioned packages BRMS and Blavaan in R for simplifying the use of the probabilistic programming language Stan.

Variable selection after checking correlations among the variables can be easily incorporated into the analysis (ex- gene-to-gene interaction) to aid the identification of predictive genes in biomedical research. (genome-wide association studies). Spatial and temporal variability can be factored into Bayesian general linear models.
A posterior distribution for a particular model can be used to simulate new data conditional on this distribution to assess and provides valid predictions to be used for extrapolating to future events.

Results/limitations, if any.
Bayesian approaches resulted in analyzing large-scale cancer genomic data sets to identify novel molecular changes that lead to cancer initiation and progression. It helps to identify the interactions between mutated genes and capture mutational signatures that highlight key genetic interactions with the potential to allow for genomic-based patient stratification in both clinical trials and the personalized use of therapeutics and assists in answering questions about evolutionary processes in cancer. 

Limitations:
In temporal models, posterior inference challenges are inherent to spatial and/or temporal dependencies, such as autocorrelation of parameters over time.
[@van2021]

4. Bayesian inference
These three steps (prior elicitation, posterior calculation, and robustness to prior uncertainty and model adequacy) are critical to Bayesian inference. This paper gives guidance on uncertainty evaluation for Normal linear regression problems.
The general guidance for Normal linear regression tasks is explained using metrological example. Normal linear regression model. The basis for all these inferences is estimation 
 
In Bayesian inference, all unknowns—observables (data) as well as unobservables (parameters and auxiliary variables)— are considered to be random and assigned probability dis-tributions. These distributions best summarize the available prior updates then information, and Bayesian inference knowledge about the unobservables with information about them contained in the data.
 
 -prior distribution expressing the belief
 -likelihood function as defined in expression
 -posterior distribution that combines the prior belief about the unknowns with the information contained in the data.

The prior knowledge from previous experiments can be summarized by pooling their posterior distributions. It is simpler and more robust to approximate (i.e. smooth) the average of the previous posterior distributions by a heavy-tailed, unimodal distribution from a parametric
Family. [@Klauenberg2015]


## Methods

PROBLEMS AND HEALTHCARE DATA 

1.	Conventional regression is not efficient in using longitudinal, hierarchical, and multivariate data to analyze time-varying outcomes, correlations within patients, and dealing missing data in predicting individual patient health timelines and treatments over time 
2.	Conventional diagnosis based on fixed cutoffs and rigid thresholds fails to capture and integrate the uncertainty and complex distributions of complex diagnostic tests. 
3.	In Cancer genomics / multi-omics study on high-dimensional, sparse, and multimodal data, classical regression is prone to overfitting. Without sensitivity analysis, the priors are not captured and may strongly influence results or may be biased.
Solutions
In healthcare, Bayesian Regression Bayesian regression provides flexibility, uncertainty quantification, and the ability to incorporate prior knowledge, making it superior to conventional regression in complex biomedical contexts.

METHOD - 
1.	Clone Prevalence Modeling 
•	PyClone-VI or PhyloWGS, the variant allele frequency (VAF) of each mutation is modeled as a function of:
o	latent clonal prevalence (how many cells carry the mutation),
o	tumor purity,
o	copy number state,
o	sequencing error.
VAFij∼Binomial(nij, θij)) : where θij is modeled as a regression-like function of clone prevalence + copy number.

These models regress observed sequencing reads (data level) on latent clone prevalences (parameter level). They add a hierarchical structure:
o	Clone-level latent variables shared across mutations.
o	Patient-level latent variables shared across clones.
•	Priors are specified for clone prevalence distributions and tree structures.
•	Posterior inference is made using Bayesian methods (MCMC in PhyloWGS, variational inference in PyClone-VI).


2.	Bayesian Regression – run a logistic regression in a Bayesian framework:
•	P(Disease∣Tests)∝P(Tests∣Disease)⋅P(Disease)
•	Priors encode expected prevalence; likelihood comes from test results.
•	Compared parametric vs. nonparametric Bayesian regression models to capture complex distributions.


3.	Bayesian regression models are flexible tools and ties predictors (e.g., genetic variants, omics features) to outcomes (phenotype, clone prevalence).
phenotype ~ genotype + covariates, with priors (genetic association studies)
Regression links different data modalities (For multi-omics integration)
Bayesian regression links observed variant frequencies to latent clone prevalences (hierarchical regression structure).


*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is unknown and* $\varepsilon_i$ *some errors. 

With the help of this definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. 

In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. 

The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$





## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{python}
import pandas as pd
```

```{r, warning=FALSE, echo=TRUE}

# Load Data
kable(head(murders))


ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}



```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References

Zeger, S. L., Wu, Z., Coley, Y., Fojo, A. T., Carter, B., O’Brien, K., Zandi, P., Cooke, M., Carey, V., Crainiceanu, C., Muscelli, J., Gherman, A., & Mekosh, J. (2020). Using a Bayesian Approach to Predict Patients’ Health and Response to Treatment. https://doi.org/10.25302/09.2020.ME.140820318

Chatzimichail, T., & Hatjimihail, A. T. (2023). A Bayesian Inference Based Computational Tool for Parametric and Nonparametric Medical Diagnosis. Diagnostics, 13(19). https://doi.org/10.3390/DIAGNOSTICS13193135

van de Schoot, R., Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., & Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1–26. https://doi.org/10.1038/S43586-020-00001-2;SUBJMETA=531,639,648,705,706;KWRD=SCIENTIFIC+COMMUNITY,STATISTICS

Klauenberg, K., Wübbeler, G., Mickan, B., Harris, P., & Elster, C. (2015). A tutorial on Bayesian Normal linear regression. Metrologia, 52(6), 878–892. https://doi.org/10.1088/0026-1394/52/6/878

