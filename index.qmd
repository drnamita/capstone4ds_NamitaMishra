---
title: "Writing a great story for data science projects - Fall 2025 "
subtitle: "This is a Report Template Quarto"
author: "Namita Mishra (Advisor: Dr. Cohen)"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: Capstone Projects in Data Science
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

Slides: [slides.html](slides.html){target="_blank"} ( Go to `slides.qmd`
to edit)

::: callout-important
**Remember:** Your goal is to make your audience understand and care
about your findings. By crafting a compelling story, you can effectively
communicate the value of your data science project.

Carefully read this template since it has instructions and tips to
writing!

Nice report!
:::

## Introduction

1. 

What is the goal of the paper?
The authors aimed to develop a bayesian hierarchical model for multivariate longitudinal data to predict the health status, trajectory, and likely intervention effects for each member of a clinical population in the PCORI mission, and to address questions about health care from patients and clinicians.

Why is it important?
Medical data includes DNA sequences, functional images of the brain, patient-reported outcomes and the electronic health record capturing patient’s sequence of health measurements, diagnoses, and treatments. Full use of the electronic health record (EHR) of patients could improve diagnostic accuracy and prediction of treatment effects, since the standard approaches for analyzing clinical data are not adequate for this purpose. 
The bayesian hierarchical model combines diverse sources of prior knowledge and patient data with evidence, to predict the patient’s health status, trajectory, and/or likely benefits of interventions. Visualizations of characteristics of posterior distributions can be immediately understood by clinicians and patients as relevant to their decision.

How is it solved? – methods
They applied Bayesian hierarchical regression for multivariate longitudinal patient data using open-source R-packages was developed 2 levels—time within person and persons within a population
The model comprised: the effects of exogenous (eg, age, clinical history) and endogenous (eg, current treatment) variables on the individual’s health status; multivariate health measurements for health status; the effects of health measurements at one time on subsequent interventions.
The model produces an estimate of the posterior distribution of the trend in health status for each value of the predictor variables and produces an estimate of the marginal distribution of the regression coefficients; each coefficient measures how the outcome, health status, is associated with its predictor variable (R, X).
In a larger sample, the likelihood dominates the prior distribution for key parameters such as regression coefficients. The bayesian hierarchical model is adaptable because (1) it is a likelihood-based approach.(2) use of priors (prior laboratory and clinical trials data) provide a reasonable range for the assay sensitivities that, once imposed through the prior assumptions, make the model identifiable (3) Markov chain Monte Carlo (MCMC) estimate the posterior distributions to avoid missing data and complex outcome measurements.

Results/limitations, if any.
Three case studies on pneumonia etiology in children, prostate cancer, and major mental disorders, were chosen to provide different challenges to the model development. In Prostate Cancer Case Study to correctly identify low risk patient population, they developed and applied hierarchical model to possibly reduce the risk overtreatment, complications and adverse effects from treatment, as well as financial burden, for patients (Disease reclassification). Prostate cancer software was then implemented within the JHM HER.
Limitation: the models were entirely parametric and recommend extensions to nonparametric or more flexible parametric models. To have improved approach for neuroimage or genomic data.[@Zeger2020Using]


2.	
What is the goal of the paper?
The authors aim to apply computational tool implementing Bayesian inference to calculate the posterior probability of disease diagnosis to develop three modules designed to define and compare parametric (with a fixed set of parameters)  and nonparametric distributions (which do not make a priori assumptions about the distribution’s mathematical form) and analyses National Health and Nutrition Examination Survey datasets from two separate diagnostic tests on both diseased and nondiseased populations. 

Why is it important?
Medical diagnosis is crucial for treatment and management decisions and uses conventional methods for diagnosis using clinical criteria and fixed numerical thresholds limits capturing other information about the intricate relations between diagnostic tests and the varying prevalence of diseases. The probability distributions associated with quantitative diagnostic test outcomes often demonstrate some overlap between the diseased and nondiseased groups. Dichotomous method fail to capture the complexity and heterogeneity of disease presentations across diverse populations. The applicability of the normal distribution in conventional method is critiqued, especially when dealing with clinical measurands that exhibit skewness, bimodality, or multimodality

How is it solved? – methods
To authors explored and developed specialized computational tool employing Bayesian inference (Bayesian diagnostic approach is) to calculate the posterior probability of disease diagnosis in theWolfram Language.
Bayesian paradigm, calculates and integrate prior probabilities of disease with distributions of diagnostic measurands in both diseased and nondiseased populations, the approach enables the evaluation of the information conveyed via diagnostic measurements and the combination of data from multiple diagnostic tests, to improve diagnostic accuracy and precision while introducing flexibility, adaptability, and versatility into the diagnostic process. The foundational data is crucial in establishing the essential context against which new diagnostic measurements can be compared and the absence of such normative data could potentially compromise the reliability and validity of Bayesian diagnostic methods.

Results/limitations, if any.
Nonparametric Bayesian models produce a better fit to data distributions, considering limited existing literature and emphasizes the robustness in capturing complex data distributions.
The nonparametric Bayesian probabilities for disease exhibited multimodal patterns,
in contrast to the bimodal, double sigmoidal curves generated by parametric models.

Limitations: 
•	The models were entirely parametric and recommend extensions to nonparametric or more flexible parametric models and aim to improv approach for neuroimage or genomic data.
•	Due to limited availability of scholarly publications is an issue with over-dependence on Prior Probabilities 
•	Elevated Uncertainty due to insufficient data contributes to broader confidence intervals in the computed posterior probabilities
•	Systemic bias due to unrepresentative datasets compromise the fidelity of Bayesian calculations.
•	Given the lack of comprehensive data, it is pertinent to combine Bayesian methods with other statistical and computational techniques for better diagnostic modalities. [@Chatzimichail2023]



3. 
Bayesian regression
Problem: Analysis of subpopulations that exist with tumours and their ancestral relationships 
Without examining the impact of priors through a sensitivity analysis and prior predictive checking, the researcher would not be aware of how sensitive results are to changes in the priors. 
The individual parameters have a different amount of uncertainty in priors (hyperparameters). A larger variance has a greater amount of uncertainty surrounding the mean, and vice versa. The diffuse and weakly informative priors show more spread than the informative priors, owing to their larger variances. 
Prior elicitation that derives the priors varies (data-based, experts,  or expert panels, generic expert-based). Prior results can be aligned or may not align with the likelihood and require prior sensitivity analysis to fully understand the influence of the prior on posterior estimates, depending on the sample size, subjectivity.

Solution:
Prior predictive checking can help prevent mistakes in the formalization of the priors, whether it is (informative, weakly informative, or diffuse). The normal distribution of the prior is specified by the hyperparameters (mean and variance, mean and standard deviation, or mean and precision (the inverse of the variance).
Prior predictive distribution and the data are compared on  mean and standard deviation of the data, which are used to check prior predictive performance to reflect important characteristics of the data, such as skewness. Also, it is suggested to check the prior through the prior predictive kernel distributions.

Method: Bayesian regression as the backbone of genetic association, multi-omics integration, and tumor phylogenetics.


Applications:
Bayesian approaches have provided a powerful alternative to frequentist approaches for assessing associations between genetic variants and a phenotype of interest in a population. The approach incorporated prior knowledge of phenotype relationships derived from a diagnosis classification tree, as from the International Classification of Diseases (ICD-10). 
Multi-omics data sets are better analyzed using Bayesian solutions to the problem of multimodal data integration and in large-scale cancer genomic data sets to identify molecular changes associated with cancer initiation and progression. Phylogenetic analysis of heterogeneous cancers identifies subpopulations that exist within tumours and their ancestral relationships through the analysis of single-cell and bulk tissue-sequencing data.[@van2021]

4. Bayesian inference
These three steps (prior elicitation, posterior calculation, and robustness to prior uncertainty and model adequacy) are critical to Bayesian inference. This paper gives guidance on uncertainty evaluation for Normal linear regression problems.
The general guidance for Normal linear regression tasks is explained using metrological example. Normal linear regression model. The basis for all these inferences is estimation 
 
In Bayesian inference, all unknowns—observables (data) as well as unobservables (parameters and auxiliary variables)— are considered to be random and assigned probability dis-tributions. These distributions best summarize the available prior updates then information, and Bayesian inference knowledge about the unobservables with information about them contained in the data.
 
 -prior distribution expressing the belief
 -likelihood function as defined in expression
 -posterior distribution that combines the prior belief about the unknowns with the information contained in the data.

The prior knowledge from previous experiments can be summarized by pooling their posterior distributions. It is simpler and more robust to approximate (i.e. smooth) the average of the previous posterior distributions by a heavy-tailed, unimodal distribution from a parametric
Family. [@Klauenberg2015]


## Methods

PROBLEMS AND HEALTHCARE DATA 

1.	Conventional regression is not efficient in using longitudinal, hierarchical, and multivariate data to analyze time-varying outcomes, correlations within patients, and dealing missing data in predicting individual patient health timelines and treatments over time 
2.	Conventional diagnosis based on fixed cutoffs and rigid thresholds fails to capture and integrate the uncertainty and complex distributions of complex diagnostic tests. 
3.	In Cancer genomics / multi-omics study on high-dimensional, sparse, and multimodal data, classical regression is prone to overfitting. Without sensitivity analysis, the priors are not captured and may strongly influence results or may be biased.
Solutions
In healthcare, Bayesian Regression Bayesian regression provides flexibility, uncertainty quantification, and the ability to incorporate prior knowledge, making it superior to conventional regression in complex biomedical contexts.

METHOD - 
1.	Clone Prevalence Modeling 
•	PyClone-VI or PhyloWGS, the variant allele frequency (VAF) of each mutation is modeled as a function of:
o	latent clonal prevalence (how many cells carry the mutation),
o	tumor purity,
o	copy number state,
o	sequencing error.
VAFij∼Binomial(nij, θij)) : where θij is modeled as a regression-like function of clone prevalence + copy number.

These models regress observed sequencing reads (data level) on latent clone prevalences (parameter level). They add a hierarchical structure:
o	Clone-level latent variables shared across mutations.
o	Patient-level latent variables shared across clones.
•	Priors are specified for clone prevalence distributions and tree structures.
•	Posterior inference is made using Bayesian methods (MCMC in PhyloWGS, variational inference in PyClone-VI).


2.	Bayesian Regression – run a logistic regression in a Bayesian framework:
•	P(Disease∣Tests)∝P(Tests∣Disease)⋅P(Disease)
•	Priors encode expected prevalence; likelihood comes from test results.
•	Compared parametric vs. nonparametric Bayesian regression models to capture complex distributions.


3.	Bayesian regression models are flexible tools and ties predictors (e.g., genetic variants, omics features) to outcomes (phenotype, clone prevalence).
phenotype ~ genotype + covariates, with priors (genetic association studies)
Regression links different data modalities (For multi-omics integration)
Bayesian regression links observed variant frequencies to latent clone prevalences (hierarchical regression structure).


*The common non-parametric regression model is*
$Y_i = m(X_i) + \varepsilon_i$*, where* $Y_i$ *can be defined as the sum of the regression function value* $m(x)$ *for* $X_i$*. Here* $m(x)$ *is unknown and* $\varepsilon_i$ *some errors. 

With the help of this definition, we can create the estimation for local averaging i.e.*
$m(x)$ *can be estimated with the product of* $Y_i$ *average and* $X_i$
*is near to* $x$*. 

In other words, this means that we are discovering
the line through the data points with the help of surrounding data
points. 

The estimation formula is printed below [@R-base]:*

$$
M_n(x) = \sum_{i=1}^{n} W_n (X_i) Y_i  \tag{1}
$$$W_n(x)$ *is the sum of weights that belongs to all real numbers.
Weights are positive numbers and small if* $X_i$ *is far from* $x$*.*

*Another equation:*

$$
y_i = \beta_0 + \beta_1 X_1 +\varepsilon_i
$$





## Analysis and Results

### Data Exploration and Visualization

-   Describe your data sources and collection process.

-   Present initial findings and insights through visualizations.

-   Highlight unexpected patterns or anomalies.

A study was conducted to determine how...

```{r, warning=FALSE, echo=T, message=FALSE}
# loading packages 
library(tidyverse)
library(knitr)
library(ggthemes)
library(ggrepel)
library(dslabs)
```

```{python}
import pandas as pd
```

```{r, warning=FALSE, echo=TRUE}

# Load Data
kable(head(murders))


ggplot1 = murders %>% ggplot(mapping = aes(x=population/10^6, y=total)) 

  ggplot1 + geom_point(aes(col=region), size = 4) +
  geom_text_repel(aes(label=abb)) +
  scale_x_log10() +
  scale_y_log10() +
  geom_smooth(formula = "y~x", method=lm,se = F)+
  xlab("Populations in millions (log10 scale)") + 
  ylab("Total number of murders (log10 scale)") +
  ggtitle("US Gun Murders in 2010") +
  scale_color_discrete(name = "Region")+
      theme_bw()
  

```

### Modeling and Results

-   Explain your data preprocessing and cleaning steps.

-   Present your key findings in a clear and concise manner.

-   Use visuals to support your claims.

-   **Tell a story about what the data reveals.**

```{r}



```

### Conclusion

-   Summarize your key findings.

-   Discuss the implications of your results.

## References

Zeger, S. L., Wu, Z., Coley, Y., Fojo, A. T., Carter, B., O’Brien, K., Zandi, P., Cooke, M., Carey, V., Crainiceanu, C., Muscelli, J., Gherman, A., & Mekosh, J. (2020). Using a Bayesian Approach to Predict Patients’ Health and Response to Treatment. https://doi.org/10.25302/09.2020.ME.140820318

Chatzimichail, T., & Hatjimihail, A. T. (2023). A Bayesian Inference Based Computational Tool for Parametric and Nonparametric Medical Diagnosis. Diagnostics, 13(19). https://doi.org/10.3390/DIAGNOSTICS13193135

van de Schoot, R., Depaoli, S., King, R., Kramer, B., Märtens, K., Tadesse, M. G., Vannucci, M., Gelman, A., Veen, D., Willemsen, J., & Yau, C. (2021). Bayesian statistics and modelling. Nature Reviews Methods Primers, 1(1), 1–26. https://doi.org/10.1038/S43586-020-00001-2;SUBJMETA=531,639,648,705,706;KWRD=SCIENTIFIC+COMMUNITY,STATISTICS

Klauenberg, K., Wübbeler, G., Mickan, B., Harris, P., & Elster, C. (2015). A tutorial on Bayesian Normal linear regression. Metrologia, 52(6), 878–892. https://doi.org/10.1088/0026-1394/52/6/878

